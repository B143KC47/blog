[{"title":"Panda basic","url":"/blog/2025/03/16/Introduction to machine learning/panda/","content":"(本博客基于Kaggle教材 link:https://www.kaggle.com/learn/pandas) Panda主要用于数据分析 two core objects in pandas: the DataFrame and the Series.两种主要的object(数据结构)： DataFrame(2D) 和 Series(1D) DataFrame a table (表格) 竖的为column 横的为 record &#x2F; row DataFrame 的创建跟字典一样Key:Element如： Series类似一个向量，1d array数据,类似一个list index 也可以是string Read data filepanda可以阅读csv文件 如 index_col就是可以启用csv文件夹已经弄了的index而不是创造一个新的 shape是 df的一个属性，类似查看这个一个矩阵的大小 head 是df的一个方法 会给出头五个record 保存成csv文件 Indexing, Selecting & AssigningNative Python objects provide good ways of indexing data. Pandas carries all of these over, which helps make it easy to start with. Native accessorspython原生的方式来访问DF或Series中的数据 在python 中，我们可以透过. 来access一个object的property.E.g. Book.name 也可以使用[]来选择row 或 column Indexing in pandaspandas 有自己的indexing method 如 ‘loc’ 和 ‘iloc’","date":"2025-03-16","categories":["Kaggle系列"],"tags":["ai","machine learning","kaggle"]},{"title":"Scalable Diffusion Models with Transformers","url":"/blog/2025/02/23/Image Generation/Scalable Diffusion Models with Transformers/","content":"Article Link:https://arxiv.org/pdf/2212.09748.pdf Abstract We explore a new class of diffusion models based on the transformer architecture. We train latent diffusion models of images, replacing the commonly-used U-Net backbone with a transformer that operates on latent patches. We analyze the scalability of our Diffusion Transformers (DiTs) through the lens of forward pass complexity as measured by Gflops. We find that DiTs with higher Gflops—through increased transformer depth&#x2F;width or increased number of input tokens—consistently have lower FID. In addition to possessing good scalability properties, our largest DiT-XL&#x2F;2 models outperform all prior diffusion models on the classconditional ImageNet 512 512 and 256 256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter. 我们探索了一种基于 Transformer 架构的新型扩散模型。我们训练图像的潜在扩散模型，用一个在潜在补丁上运行的 Transformer 替换了常用的 U-Net 主干网络。我们通过前向传递复杂度的视角（以 GFLOPs 衡量）分析了我们的扩散 Transformer (DiT) 的可扩展性。我们发现，具有更高 GFLOPs 的 DiT（通过增加 Transformer 的深度&#x2F;宽度或增加输入 tokens 的数量）始终具有更低的 FID。除了具有良好的可扩展性之外，我们最大的 DiT-XL&#x2F;2 模型在 classconditional ImageNet 512x512 和 256x256 基准测试中优于所有先前的扩散模型，在后者上实现了 2.27 的最先进 FID。 U-Net 架构U-Net 是一种常用于图像分割任务的深度学习架构，其核心是一个 U 形的编码-解码结构，由以下三部分组成： 编码器（Encoder）：压缩器 - 提取特征（卷积层组成，池化层） 解码器（Decoder）：解压器 - 补回特征（多个卷积块） 跳跃连接（Skip Connection）：连接编码器和解码器 复杂度说明GFLOPs（每秒十亿次浮点运算）用于衡量网络在处理数据时需要进行的运算量，包括加法、乘法等操作。 FID（Fréchet Inception Distance）是一种用于评估生成模型（如生成对抗网络GAN）生成图像质量的指标。 FID值越低，表示生成图像与真实图像越相似，质量越高","date":"2025-02-23","categories":["Image Generation"],"tags":["ai","image-generation"]},{"title":"机器学习入门","url":"/blog/2025/02/23/Introduction to machine learning/machine learning basic/","content":"(本博客内容基于Kaggle教程，感谢：https://www.kaggle.com/learn/intro-to-machine-learning) 机器学习是啥？简单说，就是让电脑从数据里学习，找到规律，然后用这些规律来做预测。 机器学习的几个步骤： 定义模型： 就像搭积木，选择用什么样的积木（算法）来搭建。 喂数据： 把数据给模型学习，让它找到数据里的规律。 做预测： 学习完后，让模型用学到的规律来预测新事物。 检验模型： 看看模型预测得准不准，好不好用。 Panda 介绍 (数据分析好帮手)Panda是Python里超常用的数据分析工具，可以帮你整理和分析数据。 数据结构 DataFrame: 像Excel表格一样，有行有列。 Series: 像一列数据，DataFrame就是由很多Series组成的。 核心功能 读取和写入数据（比如CSV、Excel文件）。 清洗和处理数据（把乱七八糟的数据整理干净）。 筛选和过滤数据（找到你想要的数据）。 统计和计算数据（算平均值、总和等等）。 基本使用 Sklearn 介绍 (机器学习工具箱)Sklearn是Python里最火的机器学习库，里面有很多现成的算法可以直接用。 核心功能 分类算法（Classification）： 比如判断邮件是不是垃圾邮件。 回归算法（Regression）： 比如预测房价。 聚类算法（Clustering）： 比如把用户分成不同的群体。 降维算法（Dimensionality Reduction）： 简化数据，去除不重要的信息。 模型选择（Model Selection）： 帮你找到最适合你的数据的算法。 主要优点 用起来简单。 文档写得很清楚。 用的人多，有问题容易找到答案。 能和NumPy、Pandas一起用，非常方便。 基本使用示例 模型检验 (看看模型靠不靠谱)模型预测出来的值和真实值肯定有差距，这个差距就是误差。 MAE (Mean Absolute Error)：平均绝对误差 就是把每个预测值的误差取绝对值，然后算个平均数。 为什么要取绝对值？因为误差有正有负，直接加起来可能会抵消掉。 MSE (Mean Squared Error)：均方误差 就是把每个预测值的误差取平方，然后算个平均数。 取平方也能避免正负抵消的问题，而且还能放大误差。 过拟合 (Overfitting) 和 欠拟合 (Underfitting) 过拟合： 模型在训练数据上表现很好，但在新的数据上表现很差。就像一个学生只会做他见过的题，考试的时候就傻眼了。 原因： 模型学得太细了，把训练数据里的噪音也当成了规律。 特点： 方差高： 模型对数据的变化很敏感。 泛化能力弱： 只能在特定数据上表现好。 模型太复杂。 欠拟合： 模型在训练数据上和新的数据上表现都不好。就像一个学生什么都没学懂，考试肯定不及格。 原因： 模型学得太粗略了，没能抓住数据里的主要规律。 特点： 模型太简单。 数据有问题。 训练时间不够。 基础模型介绍 决策树 (Decision Tree) 像一个流程图，根据不同的条件来做判断。 比如：如果房子有两个厕所，价格就高于18000；如果没有，就低于18000。 随机森林 (Random Forest) 有很多棵决策树，每棵树都用一部分数据和特征来训练。 可以避免过拟合和欠拟合，提高模型的准确性。","date":"2025-02-23","categories":["Kaggle系列"],"tags":["Machine learning","Kaggle","AI"]},{"title":"about","url":"/blog/about/index.html","content":"This is my personal website where I write about things that I find interesting. I am a software engineer and I am passionate about technology. I hope you enjoy reading my blog!","date":"2025-02-22"},{"title":"search","url":"/blog/search/index-1.html","content":"","date":"2025-03-09"},{"title":"Tags","url":"/blog/tags/index.html","content":"","date":"2025-02-23"},{"title":"","url":"/blog/categories/index.html","content":"","date":"2025-02-23"},{"title":"Search","url":"/blog/search/index.html","content":"","date":"2025-02-23"}]