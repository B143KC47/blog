[{"title":"Panda basic","url":"/blog/2025/03/16/Kaggle/panda/","content":"(本博客基于Kaggle教材 link:https://www.kaggle.com/learn/pandas) Panda：数据分析好帮手Panda 是一个强大的 Python 库，主要用于数据分析。可以把它想象成一个超级 Excel，能帮你处理各种表格数据。 Panda 有两个核心概念：DataFrame 和 Series。 DataFrame：表格数据DataFrame 就像一个表格，有行和列。 列（column）：表格中竖着的一列数据，可以理解为 Excel 中的一列。 行（record &#x2F; row）：表格中横着的一行数据，可以理解为 Excel 中的一行。 创建 DataFrame 就像创建一个字典： Key：列名 Value：列的数据 例如： Series：一列数据Series 就像一个列表，只有一列数据。可以看作是 DataFrame 的一部分。 Series 的索引也可以是字符串： 读取数据Panda 可以读取 CSV 文件，CSV 文件是一种常见的表格数据格式。 index_col=0 的作用是告诉 Panda，CSV 文件中已经有一列作为索引了，不要再自动创建新的索引。 shape 属性可以查看 DataFrame 的大小（行数和列数）： head() 方法可以查看 DataFrame 的前几行数据： 保存数据Panda 可以将 DataFrame 保存为 CSV 文件： 数据选择选取数据Panda 提供了多种选取数据的方法。 原生 Python 方式可以使用 . 和 [] 来选取数据，和 Python 中访问对象属性的方式类似。 Panda 方式：loc 和 ilocPanda 提供了 loc 和 iloc 两种方法来选取数据。 loc：使用标签（label）来选取数据，例如行索引或列名。 iloc：使用数字（integer）来选取数据，例如行号或列号。 注意： loc 和 iloc 选取数据时都是先行后列，与 Python 中常见的先列后行不同。 例如： set_index() 方法可以将 DataFrame 中已有的某一列设置为新的索引： 条件选择可以使用条件表达式来选取满足条件的数据。 返回： 可以使用 loc 方法结合条件表达式来选取数据： 相当于 SQL 中的 SELECT * FROM reviews WHERE country = 'Italy'。 可以使用多个条件： | 表示 “或” (or) & 表示 “与” (and) isin() 方法可以判断一列的值是否在给定的列表中： isnull() 和 notnull() 方法可以判断一列的值是否为空： isnull()：如果元素是缺失值，则返回 True，否则返回 False。 notnull()：如果元素不是缺失值，则返回 True，否则返回 False。 赋值可以直接给 DataFrame 添加新的列，并赋值： 可以根据现有列的值计算出新的列的值：","date":"2025-03-16","categories":["Kaggle系列"],"tags":["ai","machine learning","kaggle"]},{"title":"Scalable Diffusion Models with Transformers","url":"/blog/2025/02/23/Image Generation/Scalable Diffusion Models with Transformers/","content":"Article Link:https://arxiv.org/pdf/2212.09748.pdf Abstract We explore a new class of diffusion models based on the transformer architecture. We train latent diffusion models of images, replacing the commonly-used U-Net backbone with a transformer that operates on latent patches. We analyze the scalability of our Diffusion Transformers (DiTs) through the lens of forward pass complexity as measured by Gflops. We find that DiTs with higher Gflops—through increased transformer depth&#x2F;width or increased number of input tokens—consistently have lower FID. In addition to possessing good scalability properties, our largest DiT-XL&#x2F;2 models outperform all prior diffusion models on the classconditional ImageNet 512 512 and 256 256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter. 我们探索了一种基于 Transformer 架构的新型扩散模型。我们训练图像的潜在扩散模型，用一个在潜在补丁上运行的 Transformer 替换了常用的 U-Net 主干网络。我们通过前向传递复杂度的视角（以 GFLOPs 衡量）分析了我们的扩散 Transformer (DiT) 的可扩展性。我们发现，具有更高 GFLOPs 的 DiT（通过增加 Transformer 的深度&#x2F;宽度或增加输入 tokens 的数量）始终具有更低的 FID。除了具有良好的可扩展性之外，我们最大的 DiT-XL&#x2F;2 模型在 classconditional ImageNet 512x512 和 256x256 基准测试中优于所有先前的扩散模型，在后者上实现了 2.27 的最先进 FID。 U-Net 架构U-Net 是一种常用于图像分割任务的深度学习架构，其核心是一个 U 形的编码-解码结构，由以下三部分组成： 编码器（Encoder）：压缩器 - 提取特征（卷积层组成，池化层） 解码器（Decoder）：解压器 - 补回特征（多个卷积块） 跳跃连接（Skip Connection）：连接编码器和解码器 复杂度说明GFLOPs（每秒十亿次浮点运算）用于衡量网络在处理数据时需要进行的运算量，包括加法、乘法等操作。 FID（Fréchet Inception Distance）是一种用于评估生成模型（如生成对抗网络GAN）生成图像质量的指标。 FID值越低，表示生成图像与真实图像越相似，质量越高","date":"2025-02-23","categories":["Image Generation"],"tags":["ai","image-generation"]},{"title":"机器学习入门","url":"/blog/2025/02/23/Kaggle/machine learning basic/","content":"(本博客内容基于Kaggle教程，感谢：https://www.kaggle.com/learn/intro-to-machine-learning) 机器学习是啥？简单说，就是让电脑从数据里学习，找到规律，然后用这些规律来做预测。 机器学习的几个步骤： 定义模型： 就像搭积木，选择用什么样的积木（算法）来搭建。 喂数据： 把数据给模型学习，让它找到数据里的规律。 做预测： 学习完后，让模型用学到的规律来预测新事物。 检验模型： 看看模型预测得准不准，好不好用。 Panda 介绍 (数据分析好帮手)Panda是Python里超常用的数据分析工具，可以帮你整理和分析数据。 数据结构 DataFrame: 像Excel表格一样，有行有列。 Series: 像一列数据，DataFrame就是由很多Series组成的。 核心功能 读取和写入数据（比如CSV、Excel文件）。 清洗和处理数据（把乱七八糟的数据整理干净）。 筛选和过滤数据（找到你想要的数据）。 统计和计算数据（算平均值、总和等等）。 基本使用 Sklearn 介绍 (机器学习工具箱)Sklearn是Python里最火的机器学习库，里面有很多现成的算法可以直接用。 核心功能 分类算法（Classification）： 比如判断邮件是不是垃圾邮件。 回归算法（Regression）： 比如预测房价。 聚类算法（Clustering）： 比如把用户分成不同的群体。 降维算法（Dimensionality Reduction）： 简化数据，去除不重要的信息。 模型选择（Model Selection）： 帮你找到最适合你的数据的算法。 主要优点 用起来简单。 文档写得很清楚。 用的人多，有问题容易找到答案。 能和NumPy、Pandas一起用，非常方便。 基本使用示例 模型检验 (看看模型靠不靠谱)模型预测出来的值和真实值肯定有差距，这个差距就是误差。 MAE (Mean Absolute Error)：平均绝对误差 就是把每个预测值的误差取绝对值，然后算个平均数。 为什么要取绝对值？因为误差有正有负，直接加起来可能会抵消掉。 MSE (Mean Squared Error)：均方误差 就是把每个预测值的误差取平方，然后算个平均数。 取平方也能避免正负抵消的问题，而且还能放大误差。 过拟合 (Overfitting) 和 欠拟合 (Underfitting) 过拟合： 模型在训练数据上表现很好，但在新的数据上表现很差。就像一个学生只会做他见过的题，考试的时候就傻眼了。 原因： 模型学得太细了，把训练数据里的噪音也当成了规律。 特点： 方差高： 模型对数据的变化很敏感。 泛化能力弱： 只能在特定数据上表现好。 模型太复杂。 欠拟合： 模型在训练数据上和新的数据上表现都不好。就像一个学生什么都没学懂，考试肯定不及格。 原因： 模型学得太粗略了，没能抓住数据里的主要规律。 特点： 模型太简单。 数据有问题。 训练时间不够。 基础模型介绍 决策树 (Decision Tree) 像一个流程图，根据不同的条件来做判断。 比如：如果房子有两个厕所，价格就高于18000；如果没有，就低于18000。 随机森林 (Random Forest) 有很多棵决策树，每棵树都用一部分数据和特征来训练。 可以避免过拟合和欠拟合，提高模型的准确性。","date":"2025-02-23","categories":["Kaggle系列"],"tags":["Machine learning","Kaggle","AI"]},{"title":"about","url":"/blog/about/index.html","content":"This is my personal website where I write about things that I find interesting. I am a software engineer and I am passionate about technology. I hope you enjoy reading my blog!","date":"2025-02-22"},{"title":"Search","url":"/blog/search/index.html","content":"","date":"2025-02-23"},{"title":"search","url":"/blog/search/index-1.html","content":"","date":"2025-03-09"},{"title":"Tags","url":"/blog/tags/index.html","content":"","date":"2025-02-23"},{"title":"","url":"/blog/categories/index.html","content":"","date":"2025-02-23"}]