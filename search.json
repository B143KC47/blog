[{"title":"","url":"/blog/2025/03/13/panda/","content":"","date":"2025-03-13"},{"title":"Machine Learning Basic","url":"/blog/2025/02/23/machine learning basic/","content":"机器学习让机器学习数据，例如pattern等等 步骤： 定义模型 代入数据 预测 模型检验 Panda 介绍Panda是Python中最常用的数据分析库之一，主要功能包括： 数据结构 DataFrame: 二维表格数据结构 （就是一个table表格) Series: 一维数组数据结构 核心功能 数据读取与写入（CSV, Excel等） 数据清洗和处理 数据筛选和过滤 数据统计和计算 基本使用 Sklearn 介绍Sklearn是Python中最流行的机器学习库，主要特点包括： 核心功能 分类算法（Classification） 回归算法（Regression） 聚类算法（Clustering） 降维算法（Dimensionality Reduction） 模型选择（Model Selection） 主要优势 简单易用 文档完整 社区活跃 与NumPy和Pandas无缝集成 基本使用示例 模型检验一般会将模型的预测值与检验集想减 得到Error也就是误差MAE &#x3D; Mean Absolute Error平均绝对误差那么为什么要绝对值呢？因为正负可能抵消（所以 二次也可以）MSE &#x3D; Mean Squared Error 过拟合(Overfitting) 和 欠拟合(Underfitting)overfitting, where a model matches the training data almost perfectly.过拟合，即模型与训练数据几乎完全匹配，但在验证和其他新数据中表现不佳。(对数据的局部特征，噪音，偶然规律过度学习，无法捕捉本质特征) 过拟合特征： 高方差 泛化弱 （复杂模型与过拟合有正相关） When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called underfitting.如果一个模型无法捕捉数据中的重要区别和模式，因此即使在训练数据中也表现不佳，这就是所谓的欠拟合。 复杂度不够 数据问题 训练时间过短等 训练问题 基础模型介绍Decision Tree决策树 使用 condition例如如果这个房子有两个厕所它的价格就会是18000以上如果没有 就是18000以下 Random Forest 随机决策树 透过随机取样，使其不容易陷入 欠拟合和过拟合而发明，因为普通决策树树可能会因为过少的分支和过多的分支导致欠拟合和过拟合。而随机决策树在每棵树在训练时仅用部分数据和特征，从而减少模型对特定噪声的敏感性","date":"2025-02-23","categories":["Introduction to Machine learning"],"tags":["machine learning","kaggle","ai"]},{"title":"Scalable Diffusion Models with Transformers","url":"/blog/2025/02/23/Image Generation/Scalable Diffusion Models with Transformers/","content":"Article Link:https://arxiv.org/pdf/2212.09748.pdf Abstract We explore a new class of diffusion models based on the transformer architecture. We train latent diffusion models of images, replacing the commonly-used U-Net backbone with a transformer that operates on latent patches. We analyze the scalability of our Diffusion Transformers (DiTs) through the lens of forward pass complexity as measured by Gflops. We find that DiTs with higher Gflops—through increased transformer depth&#x2F;width or increased number of input tokens—consistently have lower FID. In addition to possessing good scalability properties, our largest DiT-XL&#x2F;2 models outperform all prior diffusion models on the classconditional ImageNet 512 512 and 256 256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter. 我们探索了一种基于 Transformer 架构的新型扩散模型。我们训练图像的潜在扩散模型，用一个在潜在补丁上运行的 Transformer 替换了常用的 U-Net 主干网络。我们通过前向传递复杂度的视角（以 GFLOPs 衡量）分析了我们的扩散 Transformer (DiT) 的可扩展性。我们发现，具有更高 GFLOPs 的 DiT（通过增加 Transformer 的深度&#x2F;宽度或增加输入 tokens 的数量）始终具有更低的 FID。除了具有良好的可扩展性之外，我们最大的 DiT-XL&#x2F;2 模型在 classconditional ImageNet 512x512 和 256x256 基准测试中优于所有先前的扩散模型，在后者上实现了 2.27 的最先进 FID。 U-Net 架构U-Net 是一种常用于图像分割任务的深度学习架构，其核心是一个 U 形的编码-解码结构，由以下三部分组成： 编码器（Encoder）：压缩器 - 提取特征（卷积层组成，池化层） 解码器（Decoder）：解压器 - 补回特征（多个卷积块） 跳跃连接（Skip Connection）：连接编码器和解码器 复杂度说明GFLOPs（每秒十亿次浮点运算）用于衡量网络在处理数据时需要进行的运算量，包括加法、乘法等操作。 FID（Fréchet Inception Distance）是一种用于评估生成模型（如生成对抗网络GAN）生成图像质量的指标。 FID值越低，表示生成图像与真实图像越相似，质量越高","date":"2025-02-23","categories":["Image Generation"],"tags":["ai","image-generation"]},{"title":"about","url":"/blog/about/index.html","content":"This is my personal website where I write about things that I find interesting. I am a software engineer and I am passionate about technology. I hope you enjoy reading my blog!","date":"2025-02-22"},{"title":"search","url":"/blog/search/index-1.html","content":"","date":"2025-03-09"},{"title":"Tags","url":"/blog/tags/index.html","content":"","date":"2025-02-23"},{"title":"Search","url":"/blog/search/index.html","content":"","date":"2025-02-23"},{"title":"","url":"/blog/categories/index.html","content":"","date":"2025-02-23"}]