[{"title":"Machine Learning Basic","url":"/blog/2025/02/23/machine learning basic/","content":"机器学习让机器学习数据，例如pattern等等 步骤： 定义模型 代入数据 预测 模型检验 模型分类1. 基于学习方式 监督学习模型：利用有标签的数据进行训练，学习输入与输出之间的映射关系。例如线性回归、逻辑回归、支持向量机、决策树等。 无监督学习模型：利用无标签的数据进行训练，发现数据中的隐藏结构。例如K均值聚类、层次聚类、DBSCAN、主成分分析（PCA）等。 强化学习模型：通过与环境交互，根据奖励信号学习最优行为策略。例如Q-learning、深度Q网络（DQN）等。 半监督学习模型：结合少量有标签数据和大量无标签数据进行训练。例如自训练、协同训练等。 迁移学习模型：将在源任务上学习到的知识迁移到目标任务中。例如预训练模型微调、特征提取等。 2. 基于模型结构 线性模型：假设输入特征与输出之间存在线性关系。例如线性回归、逻辑回归等。 树模型：基于树结构进行决策。例如决策树、随机森林、梯度提升树等。 神经网络模型：模拟人脑神经元结构，由多层神经元组成。例如多层感知机、卷积神经网络（CNN）、循环神经网络（RNN）等。 核方法模型：利用核函数将数据映射到高维空间，寻找线性关系。例如支持向量机等。 集成学习模型：通过组合多个基础模型提升性能。例如随机森林、梯度提升机（GBM）、XGBoost、LightGBM等。 3. 基于模型功能 分类模型：用于对数据进行分类，输出类别标签。例如逻辑回归、决策树、支持向量机、神经网络等。 回归模型：用于预测连续数值。例如线性回归、决策树回归、神经网络回归等。 聚类模型：用于将数据分为不同的簇。例如K均值聚类、层次聚类、DBSCAN等。 降维模型：用于减少数据的特征维度。例如主成分分析（PCA）、线性判别分析（LDA）等。 推荐模型：用于推荐系统，预测用户对物品的偏好。例如协同过滤、矩阵分解、神经网络推荐系统等。 4. 基于模型复杂度 简单模型：结构简单，参数较少，易于理解和解释。例如线性回归、决策树等。 复杂模型：结构复杂，参数较多，性能强大但解释性较差。例如深度神经网络、集成学习模型等。 Panda 介绍Panda是Python中最常用的数据分析库之一，主要功能包括： 数据结构 DataFrame: 二维表格数据结构 （就是一个table表格) Series: 一维数组数据结构 核心功能 数据读取与写入（CSV, Excel等） 数据清洗和处理 数据筛选和过滤 数据统计和计算 基本使用 Sklearn 介绍Sklearn是Python中最流行的机器学习库，主要特点包括： 核心功能 分类算法（Classification） 回归算法（Regression） 聚类算法（Clustering） 降维算法（Dimensionality Reduction） 模型选择（Model Selection） 主要优势 简单易用 文档完整 社区活跃 与NumPy和Pandas无缝集成 基本使用示例 模型检验一般会将模型的预测值与检验集想减 得到Error也就是误差MAE &#x3D; Mean Absolute Error平均绝对误差那么为什么要绝对值呢？因为正负可能抵消（所以 二次也可以）MSE &#x3D; Mean Squared Error","date":"2025-02-23","categories":["Image Generation"],"tags":["machine learning"]},{"title":"Scalable Diffusion Models with Transformers","url":"/blog/2025/02/23/Image Generation/Scalable Diffusion Models with Transformers/","content":"Article Link:https://arxiv.org/pdf/2212.09748.pdf Abstract We explore a new class of diffusion models based on the transformer architecture. We train latent diffusion models of images, replacing the commonly-used U-Net backbone with a transformer that operates on latent patches. We analyze the scalability of our Diffusion Transformers (DiTs) through the lens of forward pass complexity as measured by Gflops. We find that DiTs with higher Gflops—through increased transformer depth&#x2F;width or increased number of input tokens—consistently have lower FID. In addition to possessing good scalability properties, our largest DiT-XL&#x2F;2 models outperform all prior diffusion models on the classconditional ImageNet 512 512 and 256 256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter. 我们探索了一种基于 Transformer 架构的新型扩散模型。我们训练图像的潜在扩散模型，用一个在潜在补丁上运行的 Transformer 替换了常用的 U-Net 主干网络。我们通过前向传递复杂度的视角（以 GFLOPs 衡量）分析了我们的扩散 Transformer (DiT) 的可扩展性。我们发现，具有更高 GFLOPs 的 DiT（通过增加 Transformer 的深度&#x2F;宽度或增加输入 tokens 的数量）始终具有更低的 FID。除了具有良好的可扩展性之外，我们最大的 DiT-XL&#x2F;2 模型在 classconditional ImageNet 512x512 和 256x256 基准测试中优于所有先前的扩散模型，在后者上实现了 2.27 的最先进 FID。 U-Net 架构U-Net 是一种常用于图像分割任务的深度学习架构，其核心是一个 U 形的编码-解码结构，由以下三部分组成： 编码器（Encoder）：压缩器 - 提取特征（卷积层组成，池化层） 解码器（Decoder）：解压器 - 补回特征（多个卷积块） 跳跃连接（Skip Connection）：连接编码器和解码器 复杂度说明GFLOPs（每秒十亿次浮点运算）用于衡量网络在处理数据时需要进行的运算量，包括加法、乘法等操作。 FID（Fréchet Inception Distance）是一种用于评估生成模型（如生成对抗网络GAN）生成图像质量的指标。 FID值越低，表示生成图像与真实图像越相似，质量越高","date":"2025-02-23","categories":["Image Generation"],"tags":["ai","image-generation"]},{"title":"about","url":"/blog/about/index.html","content":"This is my personal website where I write about things that I find interesting. I am a software engineer and I am passionate about technology. I hope you enjoy reading my blog!","date":"2025-02-22"},{"title":"","url":"/blog/categories/index.html","content":"","date":"2025-02-23"},{"title":"search","url":"/blog/search/index-1.html","content":"","date":"2025-03-09"},{"title":"Search","url":"/blog/search/index.html","content":"","date":"2025-02-23"},{"title":"Tags","url":"/blog/tags/index.html","content":"","date":"2025-02-23"}]